---
title: June 08, 2021
tags: [Git, ClamAV, CSS, Apollo]
---

## 1) Git Loose Objects Warning

**Description:** Edwin has started seeing the following error in the terminal when running certain Git commands:

```txt
warning: There are too many unreachable loose objects; run 'git prune' to remove them.
Auto packing the repository in background for optimum performance.
See "git help gc" for manual housekeeping.
error: The last gc run reported the following. Please correct the root cause
and remove .git/gc.log.
Automatic cleanup will not be performed until the file is removed.
```

Git stores data as key-value pairs in the `.git/objects` directory. These objects are referenced by their content hash values and it is a chain of these references that comprises Git source control. References to particular objects are removed as they are abandoned leaving those objects "unreachable" from the source control root. These loose objects are automatically removed when housekeeping operations run during the normal course of Git usage. Apparently, in this case something is blocking the housekeeping operations thereby preventing Git from optimizing the data store.

According to the [Git documentation](https://git-scm.com/docs/git-prune):

> In most cases, users will not need to call git prune directly, but should instead call git gc, which handles pruning along with many other housekeeping tasks.

**Suggestion:** Look at the `.git/gc.log` file to see if there is any error listed therein. Run `git gc` and delete the `.git/gc.log` file in the effected repo to see if it resolves the issue. If this not work, attempt running `git prune` directly.

**Resources:**

- [Git docs on git-gc](https://git-scm.com/docs/git-gc)

## 2) Grouping CSS Properties

**Description:** The team had a brief discussion regarding standardization of the way we write CSS. Currently, Marek has been alphabetizing all CSS properties. For example:

```css
.marek-class {
  border: 1px solid black;
  bottom: 0;
  color: #ffff33;
  margin: 1rem;
  padding: 1rem;
  position: absolute;
  z-index: 1;
}
```

While this approach has the benefit of consistency, it can lead situations where related properties are not adjacent to one another. Edwin has been generally trying to follow the principles outlined by [Idiomatic CSS](https://github.com/necolas/idiomatic-css). This suggests grouping properties by category (ex. positioning, display, fonts, etc.). Taking the same properties as above, this approach would result in:

```css
.edwin-class {
  position: absolute;
  z-index: 1;
  bottom: 0;
  padding: 1rem;
  border: 1px solid black;
  margin: 1rem;
  color: #ffff33;
}
```

If we decide to follow a certain ordering scheme we should probably use a tool like [stylelint](https://stylelint.io/) to automatically format our CSS files.

## 3) Upcoming Meeting With MWP 2.0 Team

**Description:** Marek has a meeting tomorrow (June 9, 2021) at 2pm with Daniel from the Web team to set up access to a MWP 2.0 development site. As the meeting invite states:

> This is a screenshare to get Marek started in the MWP 2 development environment, for testing and debugging the social links plugin.
>
> We will be using BitBucket to check out the code, and build/deploy it to the Kubernetes dev cluster.

Beyond the practical need to test the Social Links plugin, this is a good opportunity to see how the Web team manages development environments. Hopefully, we can find some lessons or practices to apply to our own system. Questions of interest include:

- How is the environment rebuild/deployed?
- How/with what frequency is the database synced?
- How are they deploying WordPress in k8s?
- What is the provisioning and access management workflow?
- What is the gitflow for custom code? Does it differ for third party plugins?

## 4) ClamAV

**Description:** Michael is continuing to work on scanning files uploaded to Commons for viruses/malware using ClamAV. He has set up an S3 bucket in our account to store the virus definitions provided by ClamAV. We are running two lambda functions related to the virus scanning:

1. An event based lambda which runs every time an S3 object is created. This is the workhorse of ClamAV and checks the newly created object against the list of known virus definitions.
1. A periodic lambda that runs every three hours (?) to check ClamAV for updated virus definitions. When found, updated definitions are saved in a dedicated S3 bucket.

The code for these lambdas was provided by ClamAV and has been added directly via the AWS Lambda console. It is are not currently stored in any source control.

**Workflow:**

1. A user uploads a file to our S3 authoring bucket via Publisher.
1. The create object event in S3 initiates a lambda function to scan the uploaded file for known malware signatures.
1. Once the scan is complete, each object is tagged as `clean` or `infected`. Bucket policies prevent files marked as infected from being downloaded.
1. If the file is tagged as `infected`, the Lab dev team receives an SNS alert message.
1. The user is notified that their file is malicious and therefore the upload has failed (not yet implemented).

**Concerns:**

- **Performance:** While the scanning lambda tends to run in a matter of milliseconds for individual file uploads, we have not tested it at scale. We'll have to keep an eye out for it to make sure that there is no/little perceptible delay for the user uploading a file.
- **Cost:** We are already using lambda functions as part of the Cognito login flow in production. Last month we racked up over 14,000 invocations and hardly saw any costs. We currently upload about 20 press guidance documents and 4-5 graphics a day to S3. The cost at this usage level is negligible.

**Next Steps:** Michael will implement file scanning on Commons Dev today or tomorrow. Once implemented, we should all take special note of any errors or hits to performance when uploading files in this environment.

## 5) Apollo Custom Cache Merge

**Description:** While reviewing the Commons client PR #293, Edwin was curious about the [custom cache type policy](https://github.com/IIP-Design/content-commons-client/pull/293/files#diff-0a20f110091ee09aea650397f5cf201ce83c48e3c74a7e1d9573fb62f552f532) Marek added to the `withApollo` higher order component. Edwin wanted to know what prompted Marek to add the type policy and how he knew about the build-in cache merge capability.

The impetus behind this change was a console warning that fired on every upload of playbook support files. Essentially, during the operation of adding/removing files Apollo was looking at the playbook's `supportFiles` array in a shallow fashion. Since this array contains a list of objects and these object are not introspected Apollo is unable to determine whether each object's properties have been altered. As a result, the entire cache entry for that object was removed and replaced with the incoming object. While not a problem per se, this behavior can lead to a loss of data in the cache and Apollo recommends merging the existing values with the incoming ones. Marek followed the [Apollo documentation](https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-merge-function) to implement a custom merge policy which iterates through the objects in the array and merges the two versions (previous and updated) to preserve the maximum amount of data in cache.

In retrospect, the uploader only adds/removes support files from the array in their entirety, therefore it is unclear whether the cache merge is really required (since properties on the array's object will never be altered). Perhaps a better approach would have been to explicitly tell the cache to always use the incoming value. This would simply confirm the default behavior but suppress the cache optimization warnings.

<style>
  blockquote {
    background: #f1f1f1;
    border-left: 10px solid #002d74;
    margin: 1.5em 10px;
    padding: 0.5em 10px;
  }
</style>
